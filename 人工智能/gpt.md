# GPT

神经网络语言模型: NLP -> cnn/rnn -> transformer-base
求解NLP task: word2vector + ML -> pretain + fine-tuning

## 涌现&思维链

- 伸缩法则: 参数规模的扩大，任务效果持续增长
- 涌现能力: 参数规模达到某个临界点，任务效果骤然向好

**上下文学习和思维链是人工智能解决实际业务问题的核心、必要的关键能力**

- 上下文学习: LLM处理复杂任务的核心能力。临界值为700亿
- 思维链等复杂推理能力: 具备了通过prompt一步步引导模型从而完成复杂推理任务的能力。临界值为5000亿参数

`LangChain`, `Auto-GPT`等项目，都是通过思维链的方式实现LLM自动拆解，逐步完成一个任务。 核心思路都是对LLM思维链进行工程化封装，使得大模型能够根据自己的分析结果模式化调用可以执行特定任务的工具，本质都是Prompt工程的系统化实现

## prompt工程

> 为AI模型创建输入以改进给特定任务的输出过程

提示(prompt)是触发AI模型生成内容的宽泛指令; 它可以是一条语句，一段代码或一串单词，收到提示或输入后，AI模型会产生输出作为响应，输出质量很大程度受提示的影响

- zero-shot
- one-shot
- few-shot

## 训练方法

- 知识预训练: 使用原始训练数据集，进行预训练
- 任务微调: 使用特定数据集增强训练，可以强化模型在特定领域的性能
- 反馈学习: 使用RLHF进行微调, PPO
  - 监督学习: 人工标注数据集，训练一个LM
  - 训练奖励模型: 收集人工标准的模型多个输出之间的排序数据集，并训练一个奖励模型
  - 基于强化学习持续迭代模型: 使用奖励模型作为奖励函数，以PPO的方式，微调初始模型
- 推理加速: Paged Attention

## 发展方向

从决策型AI，转变成生成式AI

- 检索结合， 改善实时性和实时性
- 多模态理解和生产
- 调用外部能力