# 模型微调

- 模型并行: 网络太大，一张显卡存不下，拆分后进行模型并行训练
- 数据并行: 多个显卡同时采用数据训练网络的副本

## 分布式参数与架构

- rank: 进程的全局编号
- local_rank: 单个node上的本地编号
- node: 物理节点
- nnodes: 物理节点数量
- node_rank: 物理节点序号
- nnproc_per_node: 每个物理节点上面进程的数量
- wordsize: 全局(一个分布式任务)中, rank的数量

![分布式架构](./images/分布式架构.webp)

## deppspeed

DeepSpeed是一个由微软开发的开源深度学习优化库, 旨在提高大规模模型训练的效率和可扩展性

- 模型并行化
- 梯度累计
- 动态精度缩放
- 本地混合精度

还提供了一些辅助工具，如分布式训练管理，内存优化和模型压缩等，并基于pytorch构建，只需要简单的修改即可。 作为一个大模型训练加速库，位于模型训练框架和模型之间，用于提升训练、推理等

主要包含三部分

- API: 提供训练模型、推理模型等
- Runtime: 运行时组件，如部署训练任务到分布式设备、数据分区、模型分区、系统优化、微调、故障检测等，使用python实现
- Ops: 用C++和cuda实现底层内核，优化计算和通信，如ultrafast transformer kernel, fuse LAN kernel等

![软件架构](./images/deepspeed架构图.webp)

- 可以在训练框架上进行两部分(训练和推理分开)优化；
- 与紧密耦合的结构比，该结构可以更好的利用整个生态，且与深度集成相比，更容易维护；
- 与基础设置无关，用户可以选择喜欢的平台，如Azure ML、Azure VMs等

### 核心技术

### ZeRO(零冗余优化器)

Zero Redundancy Optimizer, 通过在数据并行进程之间划分模型状态参数、梯度和优化器来消除数据并行进程中的内存冗余。

- 数据并行: 计算效率高
- 模型并行: 模型分层处理。 显存效率最高，计算效率最低
- 流水线并行: 流水线并行模型的各层划分, 添加参数分布:

### ZeRO-Offload

能够同时利用CPU和GPU内存来训练大模型，核心是将优化器状态和梯度卸到CPU内存中, 实现13B的模型能够在V100中进行训练

### DeepSpeed Sparse Attention

基于注意力的深度学习模型(如transformer)能很好捕捉输入序列token之间的关系，但实践中受注意力计算的计算和内存资源限制。 通过洗漱注意力核(sparse attention kernel), 可以将注意力的计算和内存需求降低几个数量级

### 比特Adam

Adam是一个在大规模深度学习场景训练喜爱，有效的优化器。该优化器能有效减少跨设备分布式的计算。

- 从左到右，越来越慢: Stage 0 (DDP) > Stage 1 > Stage 2 > Stage 2 + offload > Stage 3 > Stage 3 + offloads
- 从左到右，所需GPU显存越来越少: Stage 0 (DDP) < Stage 1 < Stage 2 < Stage 2 + offload < Stage 3 < Stage 3 + offloads

## 优化设置

- batch training: 指在训练神经网络时，将数据分成小批次(batch)，每次只用一个小批次的数据进行模型参数的更新操作，而不是对整个数据集进行一次性的训练。这可以使训练过程更加高效，减少内存占用，同时也可以防止过拟合
- learning rate: 是神经网络优化算法中的一个重要超参数，它控制着每次模型参数更新的步长大小。较小的学习率可以使模型学习更加稳定，但可能会导致训练过程过慢；而较大的学习率可以加速训练过程，但可能会导致模型不稳定，甚至无法收敛
- optimizer: 是神经网络优化算法中的一种，它的作用是根据损失函数对模型的参数进行更新，以使损失函数最小化。常见的优化算法包括梯度下降、Adam、RMSprop等
- Stabilizing the Training: 指通过一些技巧，使得神经网络训练过程更加稳定，能够更快地收敛到最优解。常见的技巧包括添加正则化项、使用批归一化、使用残差连接等
