# Linux中IO模型

1、 阻塞io、非阻塞io，io复用（select，poll，以及epoll），信号驱动io，异步io
2、同步io操作请求，导致进程阻塞，直至操作完成。 异步io操作请求，不导致进程阻塞。
前四种io都是 同步io，最后一种才是异步io
3、select不允许多于一个的线程在同一个描述符集上等待，因此不使用与高性能，因为他没有有效的利用硬件的并行性
4、非阻塞io，io复用，信号驱动io。都是非阻塞的，采用的主动查询外设状态。poll和select是主动查询，不同的是select何poll可以同时查询多个文件描述符，但select有文件描述符数量限制。 而epoll采用的是回调函数式的。 信号驱动机制则是基于信号消息的。 这应该归属于被动接受消息
5、AIO，全异步，内核表所有的都干了 
6、BSD上用的时kqueue
7、BIO 同步阻塞式IO。简单理解，一个连接一个线程
      NIO 同步非阻塞IO。 简单理解， 一个请求一个线程
      AIO 异步非阻塞IO，简单理解，一个有效请求一个线程
8、当进行读写操作时， 内核会通知应用程序，有内容可读或可写。 并带一个回调函数，当完成时，再调用函数通知内核
9、一个IO操作实际上分为两个步骤，第一是通知io操作，第二世实际的io操作。 阻塞不阻塞，看第一步，异不异步，看第二步。
10、NIO是基于多路复用的。 linux下aio是通过epoll实现的。 而window下是通过 iocp实现的
11、NIO使用与连接数比较多但连接时间比较短的，例如聊天服务器。 AIO适用于链接数目多且连接时间比较长的。

select每次都会将文件描述符从用户态拷贝到内核态
select每次需要遍历全部的文件描述符
select同时可打开的文件描述符有限，是32*32=1024

epoll需要判断下就绪列表是否为空，而select需要不断遍历整个fd集合

一个红黑树，一个就绪列表，少量core cache，解决了大并发下的socket问题
执行epoll_create时，创建了红黑树和就绪链表； 
执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据; 
执行epoll_wait时立刻返回准备就绪链表里的数据即可。

epoll使用mmap完成内存共享
