# 高可用

> Kubernetes是云原生的核心技术之一，提供了容器编排和管理的能力，包括基础设施自动化、弹性扩展性、微服务架构和自动化运维等，所以Kubernetes的应用高可用架构是云原生高可用的基石

## 应用高可用

云原生应用的高可用架构设计，是应用高可用开发、部署和治理的重要前提

- 集群设计: 集群控制面和数据面的组件和节点，使用多节点、多副本高可用部署，保证K8s集群的高可用性
- 容器设计: 应用在集群中多副本部署，基于Deployment、Statefulset以及CRD等来管理应用的副本，实现应用的高可用性; 为应用配置自动弹性策略，以应对负载的动态变化。在多副本Pod的场景下，根据是否有主备角色的副本，可以分为主备形态高可用和多活形态高可用
- 资源调度: 使用K8s的调度器来实现应用的负载均衡和故障转移。使用标签和选择器来指定应用的部署节点范围，并使用亲和性、反亲和性、拓扑调度约束规则来控制应用的调度策略，实现Pod的按节点、可用区、部署集、拓扑域等不同类别的高可用
- 存储设计: 使用持久化存储来保存应用的数据，例如K8s的持久化卷来挂载存储等，以避免数据丢失。对于有状态应用，使用StatefulSet来管理有状态应用的副本和存储卷
- 故障恢复: 使用K8s的自动恢复机制来处理应用的故障。可以使用健康检查和自动重启来监测应用的健康状态，并在应用故障时自动重启或迁移应用
- 网络设计: 使用K8s的服务发现和负载均衡功能来实现应用的网络访问，可以使用Service和Ingress来暴露应用的服务
- 监控告警: 使用K8s的监控和告警系统（例如Prometheus、AlertManager等）来监控应用的运行状态，并及时发现和处理故障
- 全链路高可用设计: 全链路高可用是指云原生应用的系统和服务中，所有涉及到的组件、模块、服务和网络等环节都具备高可用性。全链路高可用是一个综合性的考虑，需要从整个系统的架构设计、组件的选择和配置、服务的部署和运维等方面进行综合考虑和实施。同时，需要根据具体的业务需求和技术要求，进行适度的折中和权衡

总之，设计K8s应用的高可用架构需要综合考虑集群、容器、资源调度、存储、故障恢复、网络以及监控告警等方面的因素，实现可靠稳定的应用高可用性架构和功能。对于已有系统的高可用改造也可以参考如上原则实施。

Kubernetes提供了多种高可用技术和机制，以确保集群和应用的高可用性。包括拓扑分布约束、PodAntiAffinity、容器健康检查和自动重启、存储冗余和持久化、服务发现和负载均衡等。这些技术和机制可以帮助构建高可用的Kubernetes集群和应用，提供稳定、可靠的服务，下面会展开介绍。

### 控制面/数据面高可用

- 控制面节点/组件: 将控制面节点和组件（如etcd、kube-apiserver、kube-controller-manager、kube-scheduler）部署在不同的可用区中
- 数据面节点: 将数据面节点分布在多个可用区

常见的控制面/数据面按可用区高可用打散的技术

- 拓扑分布约束TopologySpreadConstraints: 可以确保Pod在不同的节点和可用区之间均匀分布，以提高应用程序的高可用性和稳定性。该技术适用于工作负载Deployment、StatefulSet、DaemonSet和Job/CronJob。
  - MaxSkew: 每个拓扑区域内pod的最大偏差值
  - TopologyKey: 指定用于标识拓扑域或注释的键
  - WhenUnsatisfiable:  不满足时可选的操作有DoNotSchedule、ScheduleAnyway

### 应用反亲和

Affinity分为三类

- nodeAffinity: 以node为目标, node亲和性
- podAffinity: 以pod为目标, pod亲和性
- podAntiAffinity: 以pod为目标， pod反亲和性

Pod反亲和（PodAntiAffinity）是一种Kubernetes中的调度策略，用于在调度Pod时确保它们不会被调度到同一个节点上。这可以用于实现对Pod的节点打散，以提高应用程序的高可用性和故障隔离能力。

- RequiredDuringSchedulingIgnoredDuringExecution: 一种强制执行的策略，要求Pod之间的反亲和关系在调度时得到满足。这意味着Kubernetes调度器会尽力确保在调度Pod时，它们不会被调度到同一个节点上。然而，在调度后，如果节点资源不足或其他原因导致在同一节点上运行这些Pod成为必要，Kubernetes会忽略这个反亲和策略
- PreferredDuringSchedulingIgnoredDuringExecution: 一种偏好性的策略，它建议Pod之间保持反亲和关系，但不是强制要求。当调度器有多个选择时，它会尽量避免在同一个节点上调度这些Pod。然而如果没有其他可行的选择，调度器仍然可以在同一节点上调度这些Pod

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-run-per-node
spec:
  replicas: 3
  selector:
    matchLabels:
      app: app-run-per-node
  template:
    metadata:
      labels:
        app: app-run-per-node
    spec:
      containers:
        - name: app-container
          image: app-image
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values:
                      - app-run-per-node
              topologyKey: "kubernetes.io/hostname"
```

### 应用多副本

- 应用多活高可用: 应用的多个副本均可以接收流量并独立处理业务，可以通过HPA方式配置副本数根据负载压力触发的自动弹性实现对动态流量的自适应，例如APIServer、NginxIngressController。这种形态的高可用设计，需要考虑多副本的数据一致性和性能等问题
- 应用的主备高可用: 应用多副本中存在主副本和备副本，最常见的是一主一备，也存在一主多从等更复杂的形态，基于抢锁等方式来选主，适用于控制器等形态的组件。比如Etcd，KubeControllerManager，KubeScheduler都是主备形态的高可用应用
- PDB: PodDisruptionBudget（PDB）配置允许使用者定义一个最小可用副本数，当进行节点维护或故障时，Kubernetes将确保至少有指定数量的副本保持运行。PDB可以防止过多的副本同时终止，尤其适合多活副本处理流量型的场景，例如MessageQueue产品，从而避免服务中断

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: app-with-pdb
spec:
  replicas: 3
  selector:
    matchLabels:
      app: app-with-pdb
  template:
    metadata:
      labels:
        app: app-with-pdb
    spec:
      containers:
        - name: app-container
          image: app-container-image
          ports:
            - containerPort: 80
  ---
  apiVersion: policy/v1beta1
  kind: PodDisruptionBudget
  metadata:
    name: pdb-for-app
  spec:
    minAvailable: 2
    selector:
      matchLabels:
        app: app-with-pdb
```

### 健康检测与自愈

- 存活探针（LivenessProbes）: 用于监测容器是否仍然运行正常。如果存活探针失败（返回非200状态码），Kubernetes将会重启容器
- 就绪探针（ReadinessProbes）: 用于监测容器是否已经准备好接收流量。只有在就绪探针成功（返回200状态码）时，Kubernetes才会将流量转发给容器
- 启动探针（StartupProbes）: 启动探针用于监测容器是否正在启动过程中。与存活探针和就绪探针不同，启动探针在容器启动期间执行，并且只有在探针成功后，才会将容器标记为就绪状态。如果启动探针失败，Kubernetes会将容器标记为失败状态，并重新启动容器, 是为了解决程序启动时间长的问题
- 重启策略（RestartPolicy）
  - Always: 无论容器以任何方式退出，Kubernetes都会自动重启容器
  - OnFailure: 只有当容器以非零状态退出时，Kubernetes才会自动重启容器
  - Never: 无论容器以任何方式退出，Kubernetes都不会自动重启容器

### 应用与数据解耦

使用PersistentVolumes（PV）和PersistentVolumeClaims（PVC）来实现, 要选择合适的PersistentVolumeClaims和PersistentVolumes，需要考虑以下几个因素:

- 存储类型: 支持多种存储类型，包括本地存储、网络存储（如NFS、iSCSI等）、云提供商的持久化存储（如阿里云OSS等）以及外部存储插件（如Ceph、GlusterFS等）。根据应用程序的读写性能、数据保护和可用性要求选择适当的存储类型
- 存储容量: 根据应用程序的存储需求选择合适的存储容量。在创建PersistentVolume时，可以指定存储容量的大小范围。在创建PersistentVolumeClaim时，可以指定所需的存储容量。确保为应用程序提供足够的存储空间，以满足其数据存储需求
- 访问模式: 根据应用程序的访问模式选择适当的访问模式。Kubernetes支持多种访问模式，包括读写一致（ReadWriteOnce）、读写多次（ReadWriteMany）和只读（ReadOnlyMany）。根据应用程序的多节点访问需求选择适当的访问模式

选择合适的后端数据服务，如RDS等，需要考虑以下因素:

- 数据库类型和功能: 不同的数据库类型如关系型数据库（如MySQL、PostgreSQL）、NoSQL数据库（如MongoDB、Cassandra）等提供不同的功能和适应性。根据应用程序的数据模型和查询需求选择适当的数据库类型
- 性能和扩展性: 根据应用程序的性能要求选择后端数据服务。考虑数据库的性能指标（如吞吐量、延迟）以及其扩展性能
- 可用性和可靠性: 选择后端数据服务时要考虑其可用性和可靠性。云提供商的托管数据库服务通常提供高可用性和自动备份功能。确保选择一个能够满足应用程序的可用性和数据保护需求的后端数据服务

### 负载均衡高可用

为了减少跨可用区网络流量，提升网络性能。我们可以使用在Kubernetes1.23中引入拓扑感知提示(TopologyAwareHints)实现了拓扑感知的就近路由功能

### 虚拟节点高可用

虚拟节点（VirtualNode）支持Kubernetes应用部署在弹性容器实例之中，无需进行节点运维，按需创建，降低了预留资源浪费。为应对突发流量而进行业务的快速水平扩容，或者启动大量实例进行Job任务处理时，可能会遇到可用区对应规格实例库存不足或者指定的交换机IP耗尽等情况，从而导致创建失败

### 监控告警配置

- 应用负载副本不可用的监控告警: K8s的kube-state-metrics可以聚合分析应用负载Deployment/Statefulset/Daemonset的不可用副本数、副本总数等，基于该类指标可以发现应用是否存在不可用副本以及不可用副本占总副本数的百分比，实现服务部分受影响、全部影响的监控告警。
- 集群可用区内不健康节点百分比的监控告警: K8s的kube-controller-manager组件有统计可用区内的不健康节点数、健康节点百分比和节点总数，可以配置相关告警。

## 应用的单/多集群高可用架构

通过多地域、多集群的部署和单元化应用架构，可以在保证高可用性的前提下，克服跨地域网络传输延迟、成本和故障率的挑战。这样可以为用户提供更好的使用体验，同时确保业务的稳定性和可靠性。

- 单地域多可用区高可用集群: 基于如上介绍的高可用技术, 可以实现单个集群维度内的高可用架构
- 单地域多集群高可用+多地域多集群高可用: 业务应用采用多可用区部署模式，通过SLB对外提供服务。多地域部署和多可用区部署在本质上是相似的，但由于地域间网络传输延迟、成本和故障率的差异，需要采用不同的部署和应用架构来适应。对于平台层来说，不建议实现跨地域的Kubernetes集群，而是推荐采用多地域多集群的方式，并结合单元化应用架构来实现多地域的高可用架构。在不同的地域部署多个独立的Kubernetes集群，每个集群管理自己的节点和应用。每个地域的集群都是独立的，具有自己的Master节点和工作节点。这样可以降低跨地域的网络延迟和故障率，提高应用的可用性和性能。同时，采用单元化应用架构，将应用拆分为独立的单元，每个单元在多个地域的集群中部署副本。通过负载均衡和DNS解析技术，可以实现用户请求的就近路由，将流量分发到最近的地域，减少网络延迟，并提供高可用性和容灾能力

## 业务应用

### 服务存活探针

所有的服务均接入了 `k8s` 服务健康检查探针，可以有效的自动发现服务因各种原因引起的异常，并及时重启服务。

- `startupProbe`
- `livenessProbe`
- `readinessProbe`

### 有限自愈

无状态服务

#### 服务重启策略

强制配置所有 `container` 的 `restartPolicy` 为 `Always`，强制所有无状态服务在故障时自动重启，以尽量保证程序异常退出的情况下有机会被重新拉起

#### 优雅停机

要求业务组件强制要求必须支持优雅停机。在 `pod` 内启动程序时，保证 `pod` 退出时的终止信号可以有效的发送给程序，从而触发程序内部的优雅停机功能

- 强制程序以 1 号进程启动
- `dumb-init` 模拟 1 号进程终止信号
- 配置退出前 `preStop` 命令，发送终止信号

#### 多实例支持

要求所有集成组件必须支持在 `k8s` 中可以水平扩展、多实例运行。在高可用场景下, 支持所有组件以 2 个及以上 `pod` 的形式运行，且支持通过 `k8s` 亲和性等方式，配置多个 `pod` 必须或者尽可能调度到不同物理节点，从而实现基于底层多宿主机的高可用支持

## 计算组件

推荐使用`flink on k8s` 部署方案, 高可用被设计为了两个部分:

- 基于 `flink` 自身能力的 `HA` 拉起方案
- 在 `flink` 任务异常终止后，自动的重提交机制

默认使用基于 `zookeeper` 的 `HA` 方案，并提供一键切换为 `native k8s` `HA` 方案的能力。

### 基于 zookeeper 的高可用方案

使用 zookeeper 提供 flink 高可用仲裁，基于 minio 的 s3 作为高可用存储后端，进行高可用的部署

在 flinkSession 对象中，配置参数 `spec.ha.type` 为 `zookeeper` ，即可自动打开 `HA` 配置。在此模式下，`k8s` 中所有 `jobmanager` 的连接信息以及任务信息将存储在 `zookeeper` 中。一旦 `jobmanager` 损坏重启，`flink` 将在重启后自动恢复之前运行的任务

### 基于 native k8s 的高可用方案

基于 `k8s` `configmap` 的 flink 高可用仲裁，基于 minio 的 s3 作为高可用存储后端，进行高可用的部署

在 flinkSession 对象中，配置参数 `spec.ha.type` 为 `kubernetes` ，即可自动打开 `HA` 配置。在此模式下，`k8s` 中所有 `jobmanager` 的连接信息以及任务信息将存储在 `configmap` 中。一旦 `jobmanager` 损坏重启，`flink` 将在重启后自动恢复之前运行的任务

## 存储组件

### Postgres

通过repmgr可以实现对postgres集群的：

- 设置备用服务器
- 将备用服务器提升为主服务器
- 切换主备服务器
- 显示集群中服务器的状态

在repmgr安装的pg集群中每个节点中都会运行一个repmgrd守护进程，维护节点状态，主要功能包括：

- 监控和记录副本节点性能
- 通过检测主服务器的故障并提升最合适的备用服务器来执行故障转移
- 使用用户自定义的脚本提供有关集群中事件的通知，该脚本可以执行诸如通过电子邮件发送警报等任务

集群每个节点都具备一个 repmgr.conf 配置文件，用来记录本节点的 ID、节点名称、连接信息、数据库的 PGDATA 目录等配置参数。在完成参数配置后，就可以通过 repmgr 命令实现对集群节点的 “一键式” 部署。

**选举原理：**

在发生 Auto Failover 时，备节点在尝试多次连接主节点失败后（尝试次数及尝试间隔可以通过 repmgr.conf 配置文件修改），repmgrd 会在所有备节点中选举一个候选备节点（选举机制参考下文）提升为新主节点，其他备节点去 Follow 到该新主上，形成一个新的集群。

repmgr 选举候选备节点按照以下顺序选举：LSN > Priority > Node_ID

- 系统将优先选举一个 LSN 较大的节点，作为候选备节点；
- 若 LSN 一样，会根据 Priority 优先级进行比较（该优先级是在配置文件中进行参数配置，如果 Priority 为 0，则代表该节点被禁止提升为主节点）；
- 若优先级也一样，会比较节点的 Node ID，小者会优先选举。

### Redis

集群模式为`redis-cluster`

- 集群中各个redis实例使用gossip协议相互通信, 感知各自的状态
- 当master变为fail状态时，多个slave通过类Raft协议的过程重新选主
- redis cluster client 通过集群拓扑动态感应技术，实现自动故障转移以及负载均衡

部署架构

- 单机模式: 3个master实例, 伪集群模式, 没有冗余的容错能力
- 集群模式: N个master实例, N个slave实例。每个节点部署一个master实例一个slave实例，同一个数据分片的主从实例不在同一台机器上, 具有一定的容错能力。极限条件下允许半数节点崩溃，集群正常提供服务

某些节点无法提供服务时不影响整个集群的操作。计算公式：在一个由N个主节点组成的集群中，其中每个节点都有一个副本，只有一个节点被网络分区，集群的大多数侧将保持可用，并且当两个节点被分区时，集群的大多数侧 将以1-(1/(N * 2-1))的概率保持可用

#### 集群拓扑动态感应

集群拓扑动态感应技术 (Refreshing the cluster topology view) 是一种专门用于 `RedisClusterClient` 的故障转移及负载均衡技术，被各类 `redis` 客户端广泛支持

### Minio

minio只在部署4个及以上实例能保证高可用性。

minio通过纠删码实现数据高可用。数据对象在MinIO集群中进行存储时，先进行纠删分片，后打散存储在各硬盘上。具体为：MinIO自动在集群内生成若干纠删组，每个纠删组包含一组硬盘，其数量通常为4至16块；对数据对象进行分片，默认策略是得到相同数量的数据分片和校验分片；而后通过哈希算法计算出该数据对象对应的纠删组，并将数据和校验分片存储至纠删组内的硬盘上。

### Elasticsearch

- ES 本身是一个分布式的计算集群,支持数据分片以及副本分片等机制, 提供了高可用能力。
- 通过ZenDiscovery流程和Bully算法进行选主。

- 数据高可用: 多副本机制保障
- 服务高可用: es集群中每个实例默认的角色为mdi，即有成为主节点的资格, 又可以存储数据节点, 还可以作为预处理节点。 当1个node挂掉时，其余节点会被提升成主节点, 具有一定的容错能力

### Clickhouse

- 数据高可用: 使用ReplicatedMergeTree + Distributed表引擎，实现数据的高可用。ReplicatedMergeTree引擎可以为分片增加多个副本，当某个节点挂掉时，该节点分片仍可以由其他机器上的副本替代工作，所以这样实现的分布式集群可以在挂掉至少1个节点时机器正常运行，随着集群节点数量的增加，则集群挂掉2个节点或以上可提供服务的概率也越大，至少能避免单点故障问题，集群的稳定性也更高。
- 应用高可用: ClickHouse 采用Multi-Master 多主架构，集群中的每个节点角色对等，客户端访问任意一个节点都能得到相同的效果。

### zookeeper

在zookeeper中存在三种角色：领导者（leader）、跟随者（follower）和观察者（observer）。一个 ZooKeeper 集群如果要对外提供可用的服务，那么集群中必须要有**过半**的机器（非Observer）正常工作并且彼此之间能够正常通信。

一旦 Leader 服务器出现崩溃或者由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。恢复模式将重新选举出一个新的leader，让所有的Server都恢复到一个正确的状态。

ZooKeeper 能够保证数据一致性主要依赖于 ZAB 协议的消息广播，崩溃恢复和数据同步三个过程:

- 发现：要求zookeeper集群必须选举出一个 Leader 进程，同时 Leader 会维护一个 Follower 可用客户端列表。将来客户端可以和这些 Follower节点进行通信。
- 同步：Leader 要负责将本身的数据与 Follower 完成同步，做到多副本存储。这样也是提现了CAP中的高可用和分区容错。Follower将队列中未处理完的请求消费完成后，写入本地事务日志中。
- 广播：Leader 可以接受客户端新的事务Proposal请求，将新的Proposal请求广播给所有的 Follower。

### kafka

- 副本机制：Kafka允许同一个Partition存在多个消息副本，每个Partition的副本通常由1个Leader及0个以上的Follower组成，生产者将消息直接发往对应Partition的Leader，Follower会周期地向Leader发送同步请求
- ISR机制：每个分区都有自己的一个 ISR 集合，处于 ISR 集合中的副本，意味着 follower 副本与 leader 副本保持同步状态，只有处于 ISR 集合中的副本才有资格被选举为 leader。
- 故障恢复机制：首先需要在集群所有Broker中选出一个Controller，负责各Partition的Leader选举以及Replica的重新分配。当出现Leader故障后，Controller会将Leader/Follower的变动通知到需为此作出响应的Broker。